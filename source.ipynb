{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16663/3751997310.py:5: DtypeWarning: Columns (126,128,143) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  train_1 = pd.read_csv(data_dir + 'train_1.csv')\n",
      "/tmp/ipykernel_16663/3751997310.py:6: DtypeWarning: Columns (675,676,677) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  train_2_1 = pd.read_csv(data_dir + 'train_2_1.csv')\n",
      "/tmp/ipykernel_16663/3751997310.py:7: DtypeWarning: Columns (675,676,677) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  train_2_2 = pd.read_csv(data_dir + 'train_2_2.csv')\n"
     ]
    }
   ],
   "source": [
    "# Data Directory\n",
    "data_dir = 'dataset/'\n",
    "\n",
    "# Load the data\n",
    "train_1 = pd.read_csv(data_dir + 'train_1.csv')\n",
    "train_2_1 = pd.read_csv(data_dir + 'train_2_1.csv')\n",
    "train_2_2 = pd.read_csv(data_dir + 'train_2_2.csv')\n",
    "test_1 = pd.read_csv(data_dir + 'test_1.csv')\n",
    "test_2_1 = pd.read_csv(data_dir + 'test_2_1.csv')\n",
    "test_2_2 = pd.read_csv(data_dir + 'test_2_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates based on 'id' in the additional information DataFrames\n",
    "train_2_1 = train_2_1.drop_duplicates(subset='id')\n",
    "train_2_2 = train_2_2.drop_duplicates(subset='id')\n",
    "test_2_1 = test_2_1.drop_duplicates(subset='id')\n",
    "test_2_2 = test_2_2.drop_duplicates(subset='id')\n",
    "\n",
    "# Merge the DataFrames\n",
    "train = pd.merge(train_1, train_2_1, on='id', how='left')\n",
    "train = pd.merge(train, train_2_2, on='id', how='left')\n",
    "\n",
    "test = pd.merge(test_1, test_2_1, on='id', how='left')\n",
    "test = pd.merge(test, test_2_2, on='id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "864"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Release memory by deleting unnecessary variables and forcing garbage collection\n",
    "del  test_2_1, test_2_2, train_1, train_2_1, train_2_2\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# Identify numerical and categorical columns\n",
    "numerical_cols_train = train.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_cols_train = train.select_dtypes(include=['object']).columns\n",
    "\n",
    "numerical_cols_test = test.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_cols_test = test.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Handle missing values for numerical columns train\n",
    "for col in numerical_cols_train:\n",
    "    train[col] = train[col].fillna(train[col].mean())\n",
    "# Handle missing values for categorical columns train\n",
    "for col in categorical_cols_train:\n",
    "    train[col] = train[col].fillna('missing')\n",
    "\n",
    "# Handle missing values for numerical columns test\n",
    "for col in numerical_cols_test:\n",
    "    test[col] = test[col].fillna(test[col].mean())\n",
    "# Handle missing values for categorical columns test\n",
    "for col in categorical_cols_test:\n",
    "    test[col] = test[col].fillna('missing')\n",
    "\n",
    "# # Handle outliers for numerical columns using Z-score\n",
    "# for col in numerical_cols_train:\n",
    "#     train = train[(np.abs(stats.zscore(train[col])) < 3)]\n",
    "# for col in numerical_cols_test:\n",
    "#     test = test[(np.abs(stats.zscore(test[col])) < 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select relevant features\n",
    "features = train.columns.drop(categorical_cols_train).drop('label')\n",
    "X_train = train[features]\n",
    "y_train = train['label']\n",
    "X_test = test[features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Release memory by deleting unnecessary variables and forcing garbage collection\n",
    "del train, test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Remove 'loan_id' and 'id' from the list of categorical columns if they exist\n",
    "# categorical_cols_train = [col for col in categorical_cols_train if col not in ['loan_id', 'id']]\n",
    "# categorical_cols_test = [col for col in categorical_cols_test if col not in ['loan_id', 'id']]\n",
    "\n",
    "# # Remove 'loan_id' and 'id' from the features if they exist\n",
    "# X_train = X_train.drop(columns=['loan_id', 'id'], errors='ignore')\n",
    "# X_test = X_test.drop(columns=['loan_id', 'id'], errors='ignore')\n",
    "\n",
    "# # Convert categorical columns to numerical using one-hot encoding\n",
    "# X_train = pd.get_dummies(X_train, columns=categorical_cols_train)\n",
    "# X_test = pd.get_dummies(X_test, columns=categorical_cols_test)\n",
    "\n",
    "# # Ensure the same columns in train and test after one-hot encoding\n",
    "# X_train, X_test = X_train.align(X_test, join='inner', axis=1, fill_value=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Split data for validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the XGBoost model\n",
    "model = xgb.XGBClassifier(\n",
    "    n_estimators=10000,        # Increase the number of boosting rounds\n",
    "    learning_rate=0.01,       # Reduce the learning rate\n",
    "    max_depth=20,             # Increase the maximum depth of trees\n",
    "    subsample=0.8,            # Use subsampling\n",
    "    colsample_bytree=0.8,     # Use column subsampling\n",
    "    reg_alpha=0.1,            # Increase L1 regularization\n",
    "    reg_lambda=1.0,           # Increase L2 regularization\n",
    "    eval_metric='auc',        # Evaluation metric\n",
    "    random_state=42           # Seed for reproducibility\n",
    ")\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can then make predictions on the test set\n",
    "predictions = model.predict_proba(X_test)[:, 1]  # Get probabilities for class 1\n",
    "\n",
    "# Ensure the lengths match\n",
    "# predictions = predictions[:len(test_1)]\n",
    "\n",
    "# Save predictions to a submission file\n",
    "submission = pd.DataFrame({\n",
    "    'loan_id': test_1['loan_id'],\n",
    "    'prob': predictions\n",
    "})\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
